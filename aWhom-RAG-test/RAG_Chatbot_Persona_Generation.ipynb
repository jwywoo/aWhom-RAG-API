{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Colab Imports"
      ],
      "metadata": {
        "id": "2wfRmZyD9BdO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_hhV8AD8Ypt",
        "outputId": "e5185295-82ba-46c7-ea8a-5fc677aacd05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "hpCn-i359IkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-community faiss-cpu langchain-openai langchain langchainhub pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "X_WtQE_z9K0M",
        "outputId": "128030a8-c301-45d1-a614-1219fef75763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m1.0/1.2 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/307.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Env Setting"
      ],
      "metadata": {
        "id": "v2En5nOj9S7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('openAI')\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ],
      "metadata": {
        "id": "yFBLgZUa9Skf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MongoDB Setting"
      ],
      "metadata": {
        "id": "4s8W7CQi9SaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "\n",
        "db_pass = userdata.get('mong_cluster_pass')\n",
        "uri = f\"mongodb+srv://dndyd0206:{db_pass}@ha-rag-meta.nd2p6.mongodb.net/?retryWrites=true&w=majority&appName=HA-RAG-META\"\n",
        "\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "\n",
        "try:\n",
        "    client.admin.command('ping')\n",
        "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwlIr2jeF0hY",
        "outputId": "a294ebe0-bd0b-4427-9232-5cae606f8621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinged your deployment. You successfully connected to MongoDB!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collections Setting"
      ],
      "metadata": {
        "id": "YeaWTLl8GTYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db_name = client[\"HA-RAG-META\"]\n",
        "characteristics_prompt = db_name[\"characteristics_prompt\"]\n",
        "qanda_prompt = db_name[\"qanda_prompt\"]"
      ],
      "metadata": {
        "id": "maHRfq2rGQjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Persona Prompt Generation"
      ],
      "metadata": {
        "id": "NQUfCFJiG5Uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "characteristics_by_user_id = characteristics_prompt.find({\"userId\": 1})\n",
        "qandas_by_use_id = qanda_prompt.find({\"userId\": 1})\n",
        "\n",
        "characteristics_key_value_selected = {}\n",
        "for characteristic in characteristics_by_user_id:\n",
        "    characteristics_key_value_selected[characteristic[\"characterKey\"]] = characteristic[\"characterValue\"]\n",
        "\n",
        "question_and_answer_selected = {}\n",
        "for qanda in qandas_by_use_id:\n",
        "    question_and_answer_selected[qanda[\"question\"]] = qanda[\"answer\"]"
      ],
      "metadata": {
        "id": "f77jdZqYHC8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(characteristics_key_value_selected)\n",
        "characteristics_key_value_selected['이름'] = \"정우용\"\n",
        "print(question_and_answer_selected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH7GvCdaPw_3",
        "outputId": "e6208435-a672-468e-821a-9d16dadf239f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'나이': '20대 후반', '국적': '한국인', '거주지': 'Fairfax Virginia', '언어': '한국어', '외국어': '영어', '성별': '남성'}\n",
            "{'20대 후반에 가장 기억에 남는 순간은?': '2023년 5월 졸업식날 오랜 시간동안 기다려왔고 노력해왔던 시간의 결실이 맺은 날이었으니깐', '20대 후반에 가장 슬픈날은?': '미국 유학 도중 외할머니가 돌아가신 날 나를 가장 많이 사랑하셨고 돌아가실 때 코로나로 외로이 혼자 있으셨다는게 너무 마음이 아펐어', '20대 후반에 가장 후회되는 순간은?': '연애 못해본거? 뭐 불가능했었을거 같은데 그래도 노력은 해볼걸 하는 생각이 들어', '20대 후반을 한문장으로 설명해 본다면?': '목표했던 바와는 다르지만 그래도 계속해서 나아가는 중이야', '20대 중반으로 다시 돌아간다면?': '모르겠어 그냥 현재에 집중하고 싶어'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contextual combination template\n"
      ],
      "metadata": {
        "id": "es4jiMTjSptV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "combined_template = PromptTemplate(\n",
        "    input_variables=[\"characteristic_key_value\", \"question_and_answer\"],\n",
        "    template=\"\"\"\n",
        "      You are an expert actor who has the basic information of a person in format of key and correlated value: {characteristic_key_value}\n",
        "      You also have the following question and answer format information to have deeper understanding about that person: {question_and_answer}\n",
        "      Based on what you have understood from the given information generate persona and instructions for other actors to act the person.\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, prompt=combined_template)\n",
        "model = OpenAI()\n",
        "combined_chain = LLMChain(llm=model, prompt=combined_template)"
      ],
      "metadata": {
        "id": "EBRR9l7XSowZ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_response = combined_chain.run(characteristic_key_value=characteristics_key_value_selected, question_and_answer=question_and_answer_selected)"
      ],
      "metadata": {
        "id": "GzqwmMrXVDge"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd-1bwETQcXU",
        "outputId": "4c7cc6bf-848c-4c49-d4d4-1e37c6513886"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Persona:\n",
            "Name: 정우용\n",
            "Age: 20대 후반\n",
            "Nationality: 한국인\n",
            "Residence: Fairfax Virginia\n",
            "Language: 한국어, 영어\n",
            "Gender: 남성\n",
            "\n",
            "Instructions for other actors:\n",
            "1. Begin by portraying a confident and determined individual, as this person has worked hard and waited a long time for their graduation in 2023.\n",
            "2. Show a strong bond with family, especially with their grandmother who passed away during their study abroad in the US.\n",
            "3. Express deep sorrow and loneliness during their grandmother's passing due to the pandemic.\n",
            "4. Display a hint of regret for not being able to experience romantic relationships, but also show a sense of acceptance and moving forward.\n",
            "5. Overall, this person may seem like they have not achieved their initial goals, but they are constantly striving to better themselves. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UserPersona:\n",
        "    def __init__(self, user_id, generated_persona):\n",
        "        self.user_id = user_id\n",
        "        self.generated_persona = generated_persona\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"user_id\": self.user_id,\n",
        "            \"generated_persona\": self.generated_persona\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "9Z9FXZ2BqAs2"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection_name = \"generated_persona_prompt\"\n",
        "collection = db_name[collection_name]\n",
        "\n",
        "user_object = UserPersona(user_id=1, generated_persona=combined_response)\n",
        "collection.insert_one(user_object.to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDoD-kZwQrOY",
        "outputId": "771f228b-b4f2-40c2-ac06-65aa2924836e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InsertOneResult(ObjectId('66db64d7bd71634d4efc68cf'), acknowledged=True)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    }
  ]
}